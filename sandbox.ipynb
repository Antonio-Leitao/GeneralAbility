{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from scipy.spatial import distance_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "def model_create(shape, loss, metrics, X_shape):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(shape[0][0], activation=shape[0][1], input_shape=X_shape))\n",
    "\n",
    "    for layer in shape[1:]:\n",
    "        model.add(layers.Dense(layer[0], activation=layer[1]))\n",
    "\n",
    "    model.compile(optimizer='sgd', loss=loss, metrics=metrics)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def custom_loss_1(d_matrix):\n",
    "    def loss(y_true, y_pred):\n",
    "\n",
    "        dist = tf.linalg.diag_part(K.equal(y_true, d_matrix[:,-1]))\n",
    "        distances= tf.boolean_mask(d_matrix[:,:-1], dist)\n",
    "\n",
    "        distances = K.cast(distances, dtype='float32')\n",
    "        distances = K.constant(d_matrix[:,:-1], name='distance_matrix')\n",
    "\n",
    "        errors_difference =K.abs(K.transpose(K.abs(y_true - y_pred)) - K.abs(y_true - y_pred))\n",
    "        \n",
    "        errors_by_distance = tf.math.divide(errors_difference, distances+K.constant(1), name='Division')\n",
    "\n",
    "        top = K.mean(K.exp(-errors_by_distance), axis=1)\n",
    "\n",
    "        mul = K.abs(y_true - y_pred) * top\n",
    "\n",
    "        return K.mean(mul)\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def custom_loss_2(d_matrix):\n",
    "    def loss(y_true, y_pred):\n",
    "        return K.mean(K.square(y_pred - y_true) + K.square(), axis=-1)\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "class Generalization(tf.keras.callbacks.Callback):\n",
    "\n",
    "    def __init__(self, train, test, d_matrix):\n",
    "        super(Generalization, self).__init__()\n",
    "        self.test = test\n",
    "        self.train = train\n",
    "        self.dist = d_matrix\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        logs['gen_score'] = float('-inf')\n",
    "\n",
    "        X_train, y_train = self.train[0], self.train[1]\n",
    "        X_test, y_test = self.test[0], self.test[1]\n",
    "\n",
    "        y_train_pred = self.model.predict(X_train)\n",
    "        y_test_pred = self.model.predict(X_test)\n",
    "\n",
    "        k = len(y_train_pred) - 1\n",
    "\n",
    "        NN = np.array([np.argsort(self.dist[:, i], axis=0)[:k] for i in range(self.dist.shape[1])])\n",
    "        \n",
    "        p_x = [np.mean([np.exp(\n",
    "            -np.divide(np.abs(np.abs(y_test_pred[i] - y_test[i]) - np.abs(y_train_pred[j] - y_train[j])),\n",
    "                       self.dist[j, i] + 1)) for j in NN[i]]) for i in range(len(y_test))]\n",
    "        \n",
    "        M = np.abs(y_test_pred - y_test) * p_x\n",
    "        score = np.mean(M)\n",
    "        \n",
    "        logs['gen_score'] = np.round(score, 5)\n",
    "        logs['p_score'] = np.round(p_x)\n",
    "\n",
    "\n",
    "class GEN_NN_benchmark:\n",
    "    def __init__(self, model_function, model_shape, loss_function, metrics, callback, filename):\n",
    "        self.filename = filename\n",
    "        self.model_shape = model_shape\n",
    "        self.loss = loss_function\n",
    "        self.metric = metrics\n",
    "        self.model_function = model_function\n",
    "        self.results = []\n",
    "        self.callback = callback\n",
    "\n",
    "    def build(self, X, y, partition_ratio, partition_seed):\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X, y, test_size=partition_ratio,\n",
    "                                                                                random_state=partition_seed)\n",
    "\n",
    "        self.X_train = StandardScaler().fit_transform(self.X_train)\n",
    "        self.y_train = StandardScaler().fit_transform(self.y_train.reshape(-1, 1))\n",
    "\n",
    "        self.batch_size = int(len(self.X_train))\n",
    "\n",
    "        self.X_test = StandardScaler().fit_transform(self.X_test)\n",
    "        self.y_test = StandardScaler().fit_transform(self.y_test.reshape(-1, 1))\n",
    "\n",
    "        self.d_train = np.c_[distance_matrix(np.c_[self.X_train, self.y_train], np.c_[self.X_train, self.y_train]), self.y_train]\n",
    "        \n",
    "        self.d_test = distance_matrix(self.y_train, self.y_test)\n",
    "        \n",
    "        if not isinstance(self.loss, str):\n",
    "            built_loss = self.loss(self.d_train)\n",
    "        else:\n",
    "            built_loss = self.loss\n",
    "\n",
    "\n",
    "        self.model = self.model_function(self.model_shape, built_loss, self.metric,\n",
    "                                         (self.X_train.shape[1],))\n",
    "\n",
    "        self.call = self.callback(train=(self.X_train, self.y_train), test=(self.X_test, self.y_test),\n",
    "                                      d_matrix=self.d_test)\n",
    "\n",
    "    def benchmark(self, seeds, epochs, datasets, example=0):\n",
    "\n",
    "        if example:\n",
    "            print('a')\n",
    "\n",
    "        else:\n",
    "            for dataset in datasets:\n",
    "                print(dataset)\n",
    "                if dataset == 'RESID_BUILD_SALE_PRICE':\n",
    "                    data = pd.read_csv('data\\\\' + dataset + '.txt', header=None, sep='     ', error_bad_lines=False)\n",
    "                else:\n",
    "                    data = pd.read_csv('data\\\\' + dataset + '.txt', header=None, sep='\\t', error_bad_lines=False)\n",
    "\n",
    "                X = data[data.columns[:-1]].values\n",
    "                y = data[data.columns[-1]].values.reshape(-1, 1)\n",
    "                \n",
    "                X, y = make_regression(1000,20)\n",
    "\n",
    "                for seed in seeds:\n",
    "                    self.build(X, y, .33, seed)\n",
    "                    history = self.model.fit(self.X_train, self.y_train,# validation_data=(self.X_test, self.y_test),\n",
    "                                             epochs=epochs, batch_size=self.batch_size, verbose=0, callbacks=[self.call])\n",
    "                    \n",
    "                    train_pred = self.model.predict(self.X_train).flatten()\n",
    "                    test_pred = self.model.predict(self.X_test).flatten()\n",
    "                    test_p_x = history.history['p_score'][-1]\n",
    "                    \n",
    "                    self.results.append([seed, dataset, train_pred, test_pred, test_p_x])\n",
    "                    \n",
    "                    \n",
    "\n",
    "                \n",
    "            np.save(self.filename, self.results)\n",
    "            return self.results, self.model, self.y_test, self.X_test\n",
    "                \n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONCRETE\n",
      "21.051690101623535\n",
      "CONCRETE\n",
      "19.034443378448486\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "seeds = [20,30,42,50]\n",
    "epochs = 2\n",
    "datasets = ['CONCRETE']\n",
    "\n",
    "\n",
    "tik = time.time()\n",
    "test = GEN_NN_benchmark(model_create, [[10, 'relu'] * 5, [1, 'linear']], custom_loss_1, ['mae'], Generalization, 'custom_1')\n",
    "t, model, y_test, X_test = test.benchmark(seeds, epochs, datasets)\n",
    "\n",
    "print(time.time() - tik)\n",
    "\n",
    "import time\n",
    "\n",
    "tik = time.time()\n",
    "test = GEN_NN_benchmark(model_create, [[10, 'relu'] * 5, [1, 'linear']], 'mae', ['mae'], Generalization, 'mae')\n",
    "t, model, y_test, X_test = test.benchmark(seeds, epochs, datasets)\n",
    "\n",
    "print(time.time() - tik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_custom = np.load('custom_1.npy', allow_pickle='True')\n",
    "results_control = np.load('mae.npy', allow_pickle='True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 3)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_custom[:,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.   0.75 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      " 1.   1.   0.75 1.   1.   1.   0.75 1.   1.   1.   1.   1.   1.   1.\n",
      " 0.75 1.   1.   0.75 1.   1.   1.   0.75 1.   1.   1.   0.75 0.75 1.\n",
      " 0.75 1.   1.   1.   1.   1.   0.75 0.75 1.   1.   1.   1.   1.   1.\n",
      " 1.   0.75 1.   0.75 1.   0.75 1.   1.   1.   0.75 0.75 0.75 1.   1.\n",
      " 1.   0.75 1.   1.   0.75 1.   1.   0.75 0.75 1.   0.75 0.75 1.   1.\n",
      " 0.75 1.   0.75 0.75 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      " 0.75 0.75 0.75 0.75 0.75 1.   1.   0.75 0.75 1.   1.   1.   1.   1.\n",
      " 1.   1.   1.   1.   0.75 0.75 1.   1.   1.   1.   1.   0.75 1.   1.\n",
      " 1.   0.75 1.   0.75 1.   0.75 1.   1.   1.   0.75 0.75 1.   1.   0.75\n",
      " 1.   1.   1.   0.5  1.   1.   1.   1.   1.   1.   0.75 1.   0.5  1.\n",
      " 1.   1.   1.   1.   1.   1.   1.   0.75 1.   0.5  1.   1.   1.   0.5\n",
      " 1.   1.   1.   1.   0.75 1.   1.   1.   1.   1.   1.   0.75 1.   0.75\n",
      " 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   0.75 1.   1.   1.\n",
      " 1.   1.   0.75 1.   0.75 1.   1.   0.5  0.5  1.   1.   0.75 1.   1.\n",
      " 1.   1.   1.   1.   0.75 1.   0.75 1.   1.   0.75 0.75 1.   1.   1.\n",
      " 0.75 1.   0.75 1.   1.   1.   1.   1.   1.   1.   0.75 1.   0.75 0.75\n",
      " 1.   1.   0.75 1.   1.   1.   1.   1.   1.   1.   1.   1.   0.75 1.\n",
      " 1.   1.   1.   0.75 1.   1.   1.   0.75 1.   1.   0.75 0.75 0.75 0.75\n",
      " 1.   0.75 1.   1.   1.   1.   1.   1.   1.   1.   0.75 1.   1.   1.\n",
      " 1.   1.   1.   0.75 1.   1.   0.75 1.   1.   0.75 1.   1.   1.   1.\n",
      " 1.   0.75 1.   1.   1.   1.   1.   1.   1.   0.75 1.   1.   1.   1.\n",
      " 1.   0.75 1.   0.75 1.   0.75 1.   0.75 1.   1.   0.75 1.   1.   1.\n",
      " 1.   0.75 1.   1.   0.75 1.   1.   0.75]\n",
      "[1.   1.   1.   1.   1.   0.75 1.   1.   1.   1.   1.   1.   1.   1.\n",
      " 1.   1.   1.   0.75 1.   1.   1.   1.   1.   0.75 1.   1.   0.75 1.\n",
      " 1.   1.   1.   1.   0.75 1.   1.   1.   1.   1.   1.   1.   0.75 0.75\n",
      " 1.   1.   0.75 1.   1.   1.   1.   1.   0.75 1.   1.   0.75 1.   1.\n",
      " 1.   0.75 1.   1.   1.   1.   1.   1.   1.   1.   1.   0.75 1.   1.\n",
      " 1.   1.   1.   1.   1.   1.   1.   1.   1.   0.75 1.   1.   1.   1.\n",
      " 0.75 1.   1.   1.   0.75 0.5  1.   1.   1.   1.   1.   1.   0.75 1.\n",
      " 1.   1.   1.   0.75 0.75 0.75 1.   1.   1.   1.   0.75 1.   1.   1.\n",
      " 1.   1.   0.75 1.   1.   0.75 1.   1.   1.   1.   1.   0.75 1.   1.\n",
      " 1.   1.   1.   1.   1.   0.75 1.   1.   1.   1.   1.   1.   1.   1.\n",
      " 0.75 1.   0.75 1.   1.   1.   1.   0.75 0.75 1.   1.   1.   1.   0.75\n",
      " 1.   0.75 0.75 0.75 1.   0.75 1.   1.   0.75 1.   1.   1.   0.75 1.\n",
      " 1.   0.75 1.   0.75 1.   1.   1.   1.   1.   1.   1.   1.   1.   0.75\n",
      " 1.   0.75 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      " 1.   1.   1.   1.   0.75 1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      " 1.   1.   1.   1.   0.75 0.75 1.   1.   1.   0.75 1.   1.   1.   1.\n",
      " 1.   1.   1.   1.   1.   1.   0.75 1.   1.   0.75 1.   1.   1.   1.\n",
      " 1.   1.   1.   0.75 1.   1.   1.   1.   0.75 1.   1.   1.   1.   1.\n",
      " 1.   0.75 1.   1.   0.75 1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      " 0.75 0.75 0.75 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      " 0.75 1.   1.   0.75 1.   0.75 1.   1.   1.   1.   1.   1.   1.   1.\n",
      " 1.   1.   1.   1.   0.75 1.   1.   1.   1.   0.5  1.   1.   1.   0.75\n",
      " 0.75 1.   1.   0.75 1.   1.   1.   0.75 1.   1.   1.   1.   1.   1.\n",
      " 1.   1.   1.   1.   1.   0.75 0.75 1.  ]\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(results_custom[:,-1]))\n",
    "\n",
    "print(np.mean(results_control[:,-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom = []\n",
    "control = []\n",
    "\n",
    "for i in range(4):\n",
    "    custom.append(results_custom[i][2]['gen_score'][-1])\n",
    "    control.append(results_control[i][2]['gen_score'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74201"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6735475"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

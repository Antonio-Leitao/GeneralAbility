{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from scipy.spatial import distance_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "def model_create(shape, loss, metrics, X_shape):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(shape[0][0], activation=shape[0][1], input_shape=X_shape))\n",
    "\n",
    "    for layer in shape[1:]:\n",
    "        model.add(layers.Dense(layer[0], activation=layer[1]))\n",
    "\n",
    "    model.compile(optimizer='sgd', loss=loss, metrics=metrics)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def custom_loss_1(d_matrix):\n",
    "    def loss(y_true, y_pred):\n",
    "\n",
    "        dist = tf.linalg.diag_part(K.equal(y_true, d_matrix[:,-1]))\n",
    "        distances= tf.boolean_mask(d_matrix[:,:-1], dist)\n",
    "\n",
    "        distances = K.cast(distances, dtype='float32')\n",
    "        distances = K.constant(d_matrix[:,:-1], name='distance_matrix')\n",
    "\n",
    "        errors_difference =K.abs(K.transpose(K.abs(y_true - y_pred)) - K.abs(y_true - y_pred))\n",
    "        \n",
    "        errors_by_distance = tf.math.divide(errors_difference, distances+K.constant(1), name='Division')\n",
    "\n",
    "        top = K.mean(K.exp(-errors_by_distance), axis=1)\n",
    "\n",
    "        mul = K.abs(y_true - y_pred) * top\n",
    "\n",
    "        return K.mean(mul)\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def custom_loss_2(d_matrix):\n",
    "    def loss(y_true, y_pred):\n",
    "        return K.mean(K.square(y_pred - y_true) + K.square(), axis=-1)\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "class Generalization(tf.keras.callbacks.Callback):\n",
    "\n",
    "    def __init__(self, train, test, d_matrix):\n",
    "        super(Generalization, self).__init__()\n",
    "        self.test = test\n",
    "        self.train = train\n",
    "        self.dist = d_matrix\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        logs['gen_score'] = float('-inf')\n",
    "\n",
    "        X_train, y_train = self.train[0], self.train[1]\n",
    "        X_test, y_test = self.test[0], self.test[1]\n",
    "\n",
    "        y_train_pred = self.model.predict(X_train)\n",
    "        y_test_pred = self.model.predict(X_test)\n",
    "\n",
    "        k = len(y_train_pred) - 1\n",
    "\n",
    "        NN = np.array([np.argsort(self.dist[:, i], axis=0)[:k] for i in range(self.dist.shape[1])])\n",
    "        \n",
    "        p_x = [np.mean([np.exp(\n",
    "            -np.divide(np.abs(np.abs(y_test_pred[i] - y_test[i]) - np.abs(y_train_pred[j] - y_train[j])),\n",
    "                       self.dist[j, i] + 1)) for j in NN[i]]) for i in range(len(y_test))]\n",
    "        \n",
    "        M = np.abs(y_test_pred - y_test) * p_x\n",
    "        score = np.mean(M)\n",
    "        \n",
    "        logs['gen_score'] = np.round(score, 5)\n",
    "        logs['p_score'] = p_x\n",
    "\n",
    "\n",
    "class GEN_NN_benchmark:\n",
    "    def __init__(self, model_function, model_shape, loss_function, metrics, callback, filename):\n",
    "        self.filename = filename\n",
    "        self.model_shape = model_shape\n",
    "        self.loss = loss_function\n",
    "        self.metric = metrics\n",
    "        self.model_function = model_function\n",
    "        self.results = []\n",
    "        self.callback = callback\n",
    "\n",
    "    def build(self, X, y, partition_ratio, partition_seed):\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X, y, test_size=partition_ratio,\n",
    "                                                                                random_state=partition_seed)\n",
    "\n",
    "        self.X_train = StandardScaler().fit_transform(self.X_train)\n",
    "        self.y_train = StandardScaler().fit_transform(self.y_train.reshape(-1, 1))\n",
    "\n",
    "        self.batch_size = int(len(self.X_train))\n",
    "\n",
    "        self.X_test = StandardScaler().fit_transform(self.X_test)\n",
    "        self.y_test = StandardScaler().fit_transform(self.y_test.reshape(-1, 1))\n",
    "\n",
    "        self.d_train = np.c_[distance_matrix(np.c_[self.X_train, self.y_train], np.c_[self.X_train, self.y_train]), self.y_train]\n",
    "        \n",
    "        self.d_test = distance_matrix(self.y_train, self.y_test)\n",
    "        \n",
    "        if not isinstance(self.loss, str):\n",
    "            built_loss = self.loss(self.d_train)\n",
    "        else:\n",
    "            built_loss = self.loss\n",
    "\n",
    "\n",
    "        self.model = self.model_function(self.model_shape, built_loss, self.metric,\n",
    "                                         (self.X_train.shape[1],))\n",
    "\n",
    "        self.call = self.callback(train=(self.X_train, self.y_train), test=(self.X_test, self.y_test),\n",
    "                                      d_matrix=self.d_test)\n",
    "\n",
    "    def benchmark(self, seeds, epochs, datasets, example=0):\n",
    "\n",
    "        if example:\n",
    "            print('a')\n",
    "\n",
    "        else:\n",
    "            for dataset in datasets:\n",
    "                print(dataset)\n",
    "                if dataset == 'RESID_BUILD_SALE_PRICE':\n",
    "                    data = pd.read_csv('data\\\\' + dataset + '.txt', header=None, sep='     ', error_bad_lines=False)\n",
    "                else:\n",
    "                    data = pd.read_csv('data\\\\' + dataset + '.txt', header=None, sep='\\t', error_bad_lines=False)\n",
    "\n",
    "                X = data[data.columns[:-1]].values\n",
    "                y = data[data.columns[-1]].values.reshape(-1, 1)\n",
    "                \n",
    "                X, y = make_regression(1000,20)\n",
    "\n",
    "                for seed in seeds:\n",
    "                    self.build(X, y, .33, seed)\n",
    "                    history = self.model.fit(self.X_train, self.y_train,# validation_data=(self.X_test, self.y_test),\n",
    "                                             epochs=epochs, batch_size=self.batch_size, verbose=0, callbacks=[self.call])\n",
    "                    \n",
    "                    train_pred = self.model.predict(self.X_train).flatten()\n",
    "                    test_pred = self.model.predict(self.X_test).flatten()\n",
    "                    test_p_x = history.history['p_score'][-1].flatten()\n",
    "                    \n",
    "                    self.results.append([seed, dataset, train_pred, test_pred, test_p_x])\n",
    "                    \n",
    "                    \n",
    "\n",
    "                \n",
    "            np.save(self.filename, self.results)\n",
    "            return self.results, self.model, self.y_test, self.X_test\n",
    "                \n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONCRETE\n",
      "22.97202444076538\n",
      "CONCRETE\n",
      "28.19946026802063\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "seeds = [20,30,42,50]\n",
    "epochs = 2\n",
    "datasets = ['CONCRETE']\n",
    "\n",
    "\n",
    "tik = time.time()\n",
    "test = GEN_NN_benchmark(model_create, [[10, 'relu'] * 5, [1, 'linear']], custom_loss_1, ['mae'], Generalization, 'custom_1')\n",
    "t, model, y_test, X_test = test.benchmark(seeds, epochs, datasets)\n",
    "\n",
    "print(time.time() - tik)\n",
    "\n",
    "import time\n",
    "\n",
    "tik = time.time()\n",
    "test = GEN_NN_benchmark(model_create, [[10, 'relu'] * 5, [1, 'linear']], 'mae', ['mae'], Generalization, 'mae')\n",
    "t, model, y_test, X_test = test.benchmark(seeds, epochs, datasets)\n",
    "\n",
    "print(time.time() - tik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "330"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results_custom[2][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "results_control = np.load('results/test_control.npy', allow_pickle='True')\n",
    "#results_control = np.load('mae.npy', allow_pickle='True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results(array):\n",
    "    df = pd.DataFrame([])\n",
    "    for _ in range(len(array)): \n",
    "        seed = int(results_control[_][0])\n",
    "        dataset = results_control[_][1]\n",
    "        train_mae = np.mean(np.abs(results_control[_][2]))\n",
    "        test_mae = np.mean(np.abs(results_control[_][3]))\n",
    "        gen_score = np.mean(np.abs(results_control[_][3])*np.abs(results_control[_][4]))\n",
    "        df = df.append([[seed,dataset,train_mae,test_mae,gen_score]])\n",
    "        \n",
    "    df.columns = ['seed', 'dataset', 'Train Mae', 'Test Mae', 'Gen Score']\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seed</th>\n",
       "      <th>dataset</th>\n",
       "      <th>Train Mae</th>\n",
       "      <th>Test Mae</th>\n",
       "      <th>Gen Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>CONCRETE</td>\n",
       "      <td>0.658808</td>\n",
       "      <td>0.626002</td>\n",
       "      <td>0.419010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>CONCRETE</td>\n",
       "      <td>0.537514</td>\n",
       "      <td>0.509230</td>\n",
       "      <td>0.330003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>CONCRETE</td>\n",
       "      <td>0.360447</td>\n",
       "      <td>0.378145</td>\n",
       "      <td>0.248624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>CONCRETE</td>\n",
       "      <td>0.302420</td>\n",
       "      <td>0.302872</td>\n",
       "      <td>0.225703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>CONCRETE</td>\n",
       "      <td>0.560903</td>\n",
       "      <td>0.600005</td>\n",
       "      <td>0.421027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>CONCRETE</td>\n",
       "      <td>0.645432</td>\n",
       "      <td>0.700900</td>\n",
       "      <td>0.455868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>CONCRETE</td>\n",
       "      <td>0.760387</td>\n",
       "      <td>0.736678</td>\n",
       "      <td>0.456643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>CONCRETE</td>\n",
       "      <td>0.557450</td>\n",
       "      <td>0.567494</td>\n",
       "      <td>0.389806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>CONCRETE</td>\n",
       "      <td>0.941138</td>\n",
       "      <td>0.972364</td>\n",
       "      <td>0.564089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>CONCRETE</td>\n",
       "      <td>1.470004</td>\n",
       "      <td>1.441199</td>\n",
       "      <td>0.866058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   seed   dataset  Train Mae  Test Mae  Gen Score\n",
       "0     0  CONCRETE   0.658808  0.626002   0.419010\n",
       "0     1  CONCRETE   0.537514  0.509230   0.330003\n",
       "0     2  CONCRETE   0.360447  0.378145   0.248624\n",
       "0     3  CONCRETE   0.302420  0.302872   0.225703\n",
       "0     4  CONCRETE   0.560903  0.600005   0.421027\n",
       "0     5  CONCRETE   0.645432  0.700900   0.455868\n",
       "0     6  CONCRETE   0.760387  0.736678   0.456643\n",
       "0     7  CONCRETE   0.557450  0.567494   0.389806\n",
       "0     8  CONCRETE   0.941138  0.972364   0.564089\n",
       "0     9  CONCRETE   1.470004  1.441199   0.866058"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results(results_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": [
    "if not np.array([1,0]).all():\n",
    "    print('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom = []\n",
    "control = []\n",
    "\n",
    "for i in range(4):\n",
    "    custom.append(results_custom[i][2]['gen_score'][-1])\n",
    "    control.append(results_control[i][2]['gen_score'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74201"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6735475"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
